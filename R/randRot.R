





#' Decomposition of the design matrix for random rotation generation
#'
#' Full QR decomposition of the design matrix \code{X}. No argument checks are performed, see \code{Details}.
#'
#' @param X Design matrix as generated by \code{\link[stats:model.matrix]{model.matrix}}.
#' @param coef.d Non-\code{H0} coefficients.
#'
#' @return A \code{\link[base:list]{list}} object containing matrices \code{Xd}, \code{Xhe} and rank of the qr decomposition.
#' @export
#'
#' @details
#' The design matrix \code{X} is QR decomposed into \code{X = Xq Xr}. By
#' performing a full QR decomposition, \code{Xq} is automatically extended to a
#' full basis. \code{Xq} is further split into \code{Xd} and \code{Xhe}, where
#' \code{Xd} corresponds to columns \code{coef.d} (non-\code{H0} or
#' non-Null-Hypothesis columns) and \code{Xhe} correspond to all other columns
#' (\code{H0} and error columns). No argument checks are performed as this
#' function is called frequently by \code{\link[randRotation:init.randrot]{init.randrot}} when
#' weights are used.
#' See \insertCite{Langsrud2005}{randRotation} for further details.
#'
#' @author Peter Hettegger
#' @references \insertAllCited{}
#' @examples
#' design = cbind(1, rep(0:1, 5))
#' X.decomp(design)

X.decomp <- function(X = NULL, coef.d = seq_len(ncol(X)-1))
{
  qrX = qr(X)
  Xq = qr.Q(qrX, complete = TRUE)

  list(
  Xd = Xq[,coef.d, drop = FALSE],
  Xhe = Xq[,setdiff(seq_len(ncol(Xq)), coef.d), drop = FALSE],
  rank = qrX$rank
  )
}




## pre-allocate memory before executing loops

### Ev. noch folgende Methoden:
# - Batch-effect rotation (Wrappermethode für init.randrot und randrot)



# ### set following methods (see also limma's "classes.R" file):
# dim
# dimnames
# as.matrix
# "dimnames<-.RGList" <- .setdimnames

### ev. auch die [] operatoren definieren. Aber bringt das was ? Das gesamte Objekt
### müsste neu berechnet werden wenn die Anzahl an Spalten verändert wird.





#### implement contrasts and moderated statistics !





### Initialization can either be done with limma compatible objects containing $design, $E and $weights
### or by hand.
### We do not use annotation data here in order to avoid excessive copying of annotation data when the
### resampled data is executed (e.g. with lmFit or ComBat)

init.randrot <- function(Y = NULL, X = NULL, coef.h = NULL, weights = NULL, cormat = NULL)
{

  if(is.null(X)) X <- matrix(1, ncol(Y))
  if(any(dim(X) < 1)) stop("Dimensions of X (design matrix) invalid")
  if(is.null(Y) || ncol(Y) != nrow(X)) stop("Number of rows in X (design matrix) and number of columns in Y do not match")

  if(is.null(coef.h)) coef.h <- seq_len(ncol(X))
  if(length(coef.h) < 1) stop("length(coef.h) must be at least 1")
  if(length(coef.h) == 1 && coef.h == -1) coef.h = NULL
  if(!is.null(coef.h) && !all(coef.h %in% seq_len(ncol(X)))) stop("coef.h not contained in X (design matrix)")


  if(is.null(colnames(X))) colnames(X) <- seq_len(ncol(X))

  if(nrow(X) != ncol(Y)) stop("nrow(X) must match ncol(Y)")

  if(any(is.na(Y))) warning("Missing values found in Y. Missing values are tolerated as much as possible, but should be avoided. See \"init.randrot\" help page.")
  if(any(is.na(X))) warning("Missing values found in X. Missing values are tolerated as much as possible, but should be avoided. See \"init.randrot\" help page.")
  if(any(is.na(weights))) warning("Missing values found in weights. Missing values are tolerated as much as possible, but should be avoided. See \"init.randrot\" help page.")
  if(any(is.na(cormat))) warning("Missing values found in cormat. Missing values are tolerated as much as possible, but should be avoided. See \"init.randrot\" help page.")


  coef.h = sort(coef.h)
  coef.d = setdiff(seq_len(ncol(X)), coef.h)
  if(length(coef.d > 0) && length(coef.h > 0) && (min(coef.h) < max(coef.d))){
    message("coef.d ", ifelse(length(coef.d)==1, "does", "do"), " not correspond to the last columns in the design matrix.\nColumns of design matrix are rearranged")
    X = X[, c(coef.d, coef.h), drop = FALSE]
    coef.d = seq_len(length(coef.d))
    coef.h = seq_len(length(coef.h)) + length(coef.d)
  }


  # Factorisation of correlationmatrix for whitening transformation
  if(!is.null(cormat)){
    if(any(abs(cormat) > 1) | !isSymmetric(cormat)) stop("cormat has elements >1, < -1 and/or is not symmetric")
    if(ncol(cormat) != nrow(X)) stop("Dimensions of cormat must match sample size")
    if(all(abs(cormat[upper.tri(cormat),drop = FALSE]) < 1e-10)) warning("all off-diagonal entries of cormat are < 1e-10 or > -1e-10")
    if(!all(diag(cormat) == 1)) stop("Correlation matrix must have 1s in the diagonal.")

    tcholC = chol(cormat) ### cormat = t(tcholC) %*% tcholC, to be in usual naming convention of cholesky decomposition (x = LL')
    cholCinv <- drop(forwardsolve(t(tcholC), diag(ncol(tcholC))))
    tcholC = drop(tcholC)
  } else {
    tcholC <- NULL
    cholCinv <- NULL
  }


  if(!is.null(weights)) return(init.randrot.w(Y = Y, X = X, coef.h = coef.h, coef.d = coef.d, weights = weights, cormat = cormat, cholCinv = cholCinv, tcholC = tcholC))

  #### (Whitening) transformation of X and Y
  if(!is.null(cormat)){
    Y.w <- Y %*% t(cholCinv)
    X.w <- cholCinv %*% X
  } else {
    Y.w <- Y
    X.w <- X
  }

  #### QR-decomposition of X
  decomp = X.decomp(X.w, coef.d)

  Yd = Y.w %*% decomp$Xd %*% t(decomp$Xd)
  dimnames(Yd) = dimnames(Y)

  Xhe.Y.w = t(decomp$Xhe) %*% t(Y.w)

  new("init.randrot", list(X = X, Xhe.Y.w = Xhe.Y.w, Yd = Yd, Xhe = decomp$Xhe,
                           coef.d = coef.d, coef.h = coef.h, cormat = cormat, tcholC = tcholC, rank = decomp$rank))
}

init.randrot.w <- function(Y, X, coef.h, coef.d, weights, cormat, cholCinv, tcholC)
{
  if(any(weights <= 0) | any(!is.finite(weights))) stop("Weights must be finite > 0")
  w = sqrt(weights)

  #### (Whitening) transformation of Y and X and QR-decomposition of X
  if(!is.null(cormat)){
    Y.w <- (w * Y) %*% t(cholCinv)

    decomp.list = apply(w, 1, function(w.i){
      X.decomp(cholCinv %*% (w.i * X), coef.d)
    })
  } else {
    Y.w <- (w * Y)

    decomp.list = apply(w, 1, function(w.i){
      X.decomp(w.i * X, coef.d)
    })
  }


  Yd = t(sapply(seq_len(nrow(Y.w)), function(i){
    Y.w[i,,drop = FALSE] %*% decomp.list[[i]]$Xd %*% t(decomp.list[[i]]$Xd)
  }))

  dimnames(Yd) = dimnames(Y)

  Xhe.Y.w = sapply(1:nrow(Y.w), function(i){
    Y.w[i,,drop = FALSE] %*% decomp.list[[i]]$Xhe
  })

  new("init.randrot.w", list(X = X, Xhe.Y.w = Xhe.Y.w, Yd = Yd, decomp.list = decomp.list,
                             coef.d = coef.d, coef.h = coef.h, cormat = cormat, tcholC = tcholC, w = w))
}





#' Initialised random rotation class
#'
#' List-based S4 class containing all information necessary to generate randomly rotated data with the \code{\link[randRotation:randrot]{randrot}} method.
#' \code{init.randrot} and \code{init.randrot.w} objects are created with the \code{\link[randRotation:init.randrot]{init.randrot}} method.
#' @section Components:
#' The following components are included as list elements:
#' \describe{
#'   \item{\code{X}}{Original (non-transformed) design matrix.}
#'   \item{\code{Xhe}, \code{Xhe.Y.w}, \code{Yd}}{Pre-multiplied matrix products needed for generation of rotated data (\code{\link[randRotation:randrot]{randrot}}).}
#'   \item{\code{coef.h}, \code{coef.d}}{Indices of \eqn{H_0}{H0} coefficients (\code{coef.h}) and indices of all other coefficients (\code{coef.d}).}
#'   \item{\code{cormat}}{Correlation matrix, see \code{\link[randRotation:init.randrot]{init.randrot}}.}
#'   \item{\code{tcholC}}{Cholesky decomposition of cormat: \code{cormat = crossprod(tcholC)}.}
#' }
#' @export
#' @author Peter Hettegger
#' @examples
setClass("init.randrot", contains = "list")

#' Initialised random rotation class with weights
#'
#' This class is organised as its base class \code{init.randrot}, see description in \code{\link[randRotation:init.randrot-class]{init.randrot-class}}.
#' Some components are changed or added.
#' @section Components:
#' The following components are changed or as compared to \code{\link[randRotation:init.randrot-class]{init.randrot-class}}:
#' \describe{
#'   \item{\code{decomp.list}}{List containing decomposed (transformed) design matrix for each feature, see \code{\link[randRotation:X.decomp]{X.decomp}}.}
#'   \item{\code{w}}{Numeric matrix with dimensions \code{features x samples} containing component wise square root of the weight matrix, see \code{\link[randRotation:init.randrot]{init.randrot}}.}
#' }
#' @return
#' @export
#' @examples
#' @author Peter Hettegger
setClass("init.randrot.w", contains = c("init.randrot", "list"))




#' Initialised random rotation batch object
#'
#' This class contains a list of \code{init.randrot} or \code{init.randrot.w} class objects, see descriptions in \code{\link[randRotation:init.randrot-class]{init.randrot-class}} and \code{\link[randRotation:init.randrot.w-class]{init.randrot.w-class}}.
#' @return
#' @export
#' @examples
#' @author Peter Hettegger
setClass("init.batch.randrot", contains = c("list"))


#' Rotated object containing p values
#'
#' This class contains calculated statistics for the original data (\code{s0}) and rotated data (\code{stats}). See also \code{\link[randRotation:rotate.stat]{rotate.stat}}.
#' @return
#' @export
#' @examples
#' @author Peter Hettegger
setClass("rotate.stat", contains = "list")




#' Initialisation of a random rotation Object
#'
#' Initialization of a linear model for subsequent generation of randomly rotated data (\code{\link[randRotation:randrot]{randrot}}) associated with the null hypothesis
#' \eqn{H_{0}: \beta_{coef.h} = 0}{H0: \beta_coef.h = 0}. Basics of rotation tests are found in \insertCite{Langsrud2005}{randRotation}.
#'
#'
#' @param Y a data matrix with \code{features x samples} dimensions. Missing values (\code{\link[base:NA]{NA}}) are allowed but e.g. lead to NAs for all samples of the respective features in the rotated dataset and should thus be avoided. We highly recommend avoiding missing values by e.g. replacing them by imputation or removing features containing NAs.
#' @param X the design matrix of the experiment with \code{samples x coefficients} dimensions. If no design matrix is specified, intercept only model is used (design matrix with one column where all elements are \code{1}).
#' @param coef.h single integer or vector of integers specifying the \code{H_0} coefficients. \code{coef.h} should correspond to the last columns in \code{X} (see \code{Details}). By default, all coefficients are set as \code{H_0} coefficients. If \code{coef.h} is set \code{-1}, no coefficient is set as \code{H_0} coefficient.
#' @param weights numerical matrix of finite positive weights > 0. Dimensions must be equal to dimensions of \code{Y}.
#' @param cormat The sample correlation matrix with \code{samples x samples} dimensions. Must be a real symmetric positive-definite square matrix. See \code{Details} for usage in \code{init.batch.randrot}.
#'
#' @rdname init.randrot
#' @return an initialised object containing all necessary information for generating randomly rotated data (\code{\link[randRotation:randrot]{randrot}}). See \code{\link[randRotation:init.randrot-class]{init.randrot-class}}
#' @author Peter Hettegger
#' @references \insertAllCited{}
#'
#' @details
#'
#' This function performs basic initial checks and preparatory calculations for random rotation data generation, see \insertCite{Langsrud2005}{randRotation}.
#' Nomenclature of variables is mainly as in \insertCite{Langsrud2005}{randRotation}. See also package vignette for application examples.
#'
#' \code{coef.h} specifies the model coefficients associated with the null hypothesis. All other model coefficients #### continue here
#' The design matrix is rearranged so that \code{coef.h} correspond to the last columns of the design matrix. This is necessary for adequate transformation of the combined null-hypothesis \eqn{H_{0}: \beta_{coef.h} = 0}{H0: \beta_coef.h = 0} by QR decomposition.
#'
#'
#' Weights must be finite positive values greater zero. This ist necessary for model (QR) decomposition and for backtransformation of the rotated data into the original variance structure, see also \code{\link[randRotation:randrot]{randrot}}.
#' Weights as estimated e.g. by voom \insertCite{Law2014}{randRotation} are suitable and can be used without further processing. Note that due to the whitening
#' transformation (i.e. by using the arguments \code{weights} and/or \code{cormat}) the rank of the transformed design matrix \code{X} could change (become smaller),
#' which could become dangerous for the fitting procedures. If you get errors using weights, try the routine without using weights to exclude this source of errors.
#' @export
#' @seealso \code{\link[randRotation:randrot]{randrot}}
#' @examples
#'
# @import Matrix
#' @import methods
#' @importFrom stats rnorm
setGeneric("init.randrot", function(Y = NULL, X = NULL, coef.h = NULL, weights = NULL, cormat = NULL) {standardGeneric("init.randrot")})


#'
#' @return
#' @export
#' @details When using \code{init.batch.randrot}, \code{init.randrot} is called for each batch separately. When using \code{init.batch.randrot} with \code{cormat}, \code{cormat} needs to be a list of correlation matrices with one matrix for each batch. Batches are split according to \code{split(seq_along(batch), batch)}.
#'
#' @rdname init.randrot
init.batch.randrot <- function(Y = NULL, X = NULL, coef.h = NULL, batch = NULL, weights = NULL, cormat = NULL)
{

  spl1 = split(seq_along(batch), batch)

  Y.l = lapply(spl1, function(i){
    Y[,i,drop = FALSE]
  })

  X.l = lapply(spl1, function(i){
    X[i,,drop = FALSE]
  })

  weights.l = lapply(spl1, function(i){
    weights[,i,drop = FALSE]
  })


  init.randrot.l = lapply(seq_len(length(spl1)), function(i){
    cat("Initializing batch \"", names(spl1)[i], "\"\n", sep = "")
    init.randrot(Y = Y.l[[i]], X = X.l[[i]], coef.h = coef.h, weights = weights.l[[i]], cormat = cormat[[i]])
  })


  new("init.batch.randrot", list(batch.obj = init.randrot.l, split.by = spl1))

}


#' Title
#'
#' @param list This is a test
#' @param Y2 Another test
#'
#' @return
#' @rdname init.randrot
#' @export
#'
#' @examples
setMethod("init.randrot", "list",
          function(Y = NULL, X = Y$design, coef.h = NULL, weights = Y$weights, cormat = NULL){
            init.randrot(Y = Y$E, X = X, coef.h = coef.h, weights = weights, cormat = cormat)
          })





#' @export
#' @rdname init.randrot
#' @details The show method always displays the original design matrix (\code{X}), not the transformed versions.

setMethod("show", "init.randrot",
          function(object)
          {
            cat("Initialised random rotation object", if(!is.null(object$w))"(with weights)","\n\n")
            cat(dim(object$Yd)[1], "features   ", dim(object$Yd)[2], "samples\n\n")
            cat("Coefficients to test (coef.h):", colnames(object$X)[object$coef.h], "\n\n")

            cat("model matrix (X):\n")
            print(head(object$X, n = 6))
            if(nrow(object$X) > 6)cat(".\n.\n",nrow(object$X)-6, "more rows\n")

            if(!is.null(object$cormat)){
              cat("\ncorrelation matrix (cormat) - showing first 6x6 entries:\n")
              show.i = seq_len(min(6, ncol(object$cormat)))
              print(object$cormat[show.i, show.i])
              cat("\n")
            }

            if(!is.null(object$w)){
              cat("\nweights - showing first 6x6 entries:\n")
              show.i = seq_len(min(6, dim(object$w)))
              print((object$w[show.i, show.i])^2)
              cat("\n")
            }

            cat("\n\n")

          }
)

#' @export
#' @rdname init.randrot

setMethod("show", "init.batch.randrot",
          function(object)
          {
            cat("Initialised batch random rotation ojbect (with blockDesign = TRUE). In the following the structure of each batch is listed separately:\n\n")

            invisible(lapply(seq_along(object$batch.obj), function(i){
              cat("##########################\n")
              cat("     BATCH ", i)
              cat("\n##########################\n\n")

              show(object$batch.obj[[i]])
            }))
          }
)


#' Random rotation of initialised object
#'
#' Perform random data rotation of a previously initialised object (\code{\link[randRotation:init.randrot]{init.randrot}}) associated with the null hypothesis \eqn{H_{0}: \beta_{coef.h} = 0}{H0: \beta_coef.h = 0}.
#'
#'
#' @param object An initialised object
#' @param ... Further arguments are passed to \code{randorth}
#'
#' @return a numerical matrix of rotated data under the specified combined null hypothesis.
#' @export
#' @rdname randrot
#'
#' @details
#'
#' This function generates a randomly rotated dataset from an initialised randrot object (\code{\link[randRotation:init.randrot]{init.randrot}}). See also package vignette for application examples.
#' Only the numerical matrix of rotated data is returned, no design matrix, weights or other info is return for efficiency purposes.
#' restricted random rotation matrix \eqn{R_t^*}{Rt*} \deqn{R_t^* = X_dX_d' + \left[X_h \quad X_e \right] R^* \left[X_h \quad X_e \right]^\prime}{Rt* = Xd Xd' + [Xh  Xe] R* [Xh  Xe]'}
#' with ' being the transposed and \code{R*} being a (reduced) random rotation matrix with reduced dimensions ### continue here
#'
#' In the case of weighted data, for each feature a separate QR decomposition and
#' restricted random orthogonal matrix is calculated with the same reduced random rotation matrix \eqn{R*} for all features.
#' Weighted is rotated by feature wise pre-multiplying \code{Y} and \code{X} with the respective weights.
#' @author Peter Hettegger
#' @examples
setGeneric("randrot", function(object, ...) standardGeneric("randrot"))






#' @export
#' @rdname randrot

setMethod("randrot", "init.randrot",
          function(object,...){
            ### No excessive initial checks for efficiency purposes.
            R = randorth(nrow(object$Xhe.Y.w),...)

            if(is.null(object$cormat))
              (object$Yd + t(object$Xhe %*% R %*% object$Xhe.Y.w))
            else
              (object$Yd + t(object$Xhe %*% R %*% object$Xhe.Y.w)) %*% object$tcholC
          })


#' @rdname randrot
#' @export
setMethod("randrot", "init.randrot.w",
          function(object,...){
            ### No excessive initial checks for efficiency purposes.
            R = randorth(nrow(object$Xhe.Y.w),...)

            R.Xhe.Y.w = R %*% object$Xhe.Y.w

            n = length(object$decomp.list)
            Yhe = t(sapply(1:n, function(i){
              object$decomp.list[[i]]$Xhe %*% R.Xhe.Y.w[,i,drop = FALSE]
            }))

            # de-withening of Y.w
            if(is.null(object$cormat))
              (1/object$w) *  (object$Yd + Yhe)
            else
              (1/object$w) * ((object$Yd + Yhe) %*% object$tcholC)
          })




#' @rdname randrot
#' @export
setMethod("randrot", "init.batch.randrot",
          function(object,...){
            ord1 = order(unlist(object$split.by))

            ### Perform randrot for each batch an sort back to initial order as in the design matrix.
            do.call(cbind,
                    lapply(object$batch.obj, randrot, ...)
                    )[,ord1,drop=FALSE]
          })




#' Generate data rotations and calculate statistics on it
#'
#' @param initialised.obj
#' @param statistic A function that calculates a statistic from a datamatrix \code{Y} (see also \code{\link[randRotation:init.randrot]{init.randrot}}) and any further arguments passed to it by \code{statistic.args}.
#' Note that \code{\link[randRotation:p.fdr]{p.fdr}}) considers larger values of statistics significant, so one-tailed tests may require inversion and two-tailed tests may require taking absolute values.
#' The results of \code{statistic} for each resample are finally combined with \code{cbind}. Results with multiple columns are possible and handled adequately in subsequent functions (e.g. \code{\link[randRotation:p.fdr]{p.fdr}}).
#' @param statistic.args A list of arguments passed to \code{statistic}, see \code{Examples}.
#' @param R The number of resamples.
#' @param parallel
#' @param split.parallel
#' @param cl
#' @param ...
#'
#' @return
#' @export
#' @details If \code{parallel = TRUE} and no argument \code{cl} is delivered, a cluster is created with the method \code{parallel::makeCluster} with one core less than \code{parallel::detectCores()} returns.
#' So the default cluster is generated as \code{parallel::makeCluster(parallel::detectCores()-1)}. If \code{parallel = TRUE} the function calls in \code{statistic} need to be called explicitly with package name and "::".
#' So e.g. calling \code{lmFit} from the \code{limma} package is done with \code{limma::lmFit(...)}.
#'
#' Sometimes it is rewarding to split the resampling loop into smaller loops that are executed on separate cores. E.g. if \code{R = 800} it could be faster to execute 100 rotations on 8 CPUs instead of distributing all
#' 800 rotations on the 8 CPUs (due to parallelisation overhead), see also the package vignette. This splitting can be done with \code{split.parallel}. \code{split.parallel} could be logic or an integer > 0 specifying the number of cores to split the task.
#' If \code{split.parallel} is \code{TRUE}, the number of cores is retrieved with \code{foreach::getDoParWorkers()}.
#'
#'
#' @examples
#' @author Peter Hettegger
### funktioniert das auch mit weights ???
rotate.stat = function(initialised.obj, statistic, statistic.args = list(), R = 10, parallel = FALSE, split.parallel = TRUE, cl = NULL, ...){

  if(R<1) stop("R must be at least 1")

  if(parallel){
    if(is.null(cl)) {
      cl <- parallel::makeCluster(parallel::detectCores()-1, type = ifelse(.Platform$OS.type == "windows", "PSOCK", "FORK"))
      doParallel::registerDoParallel(cl)
      on.exit(parallel::stopCluster(cl))
    }

    f1 = foreach::`%dopar%`

  } else
    f1 = foreach::`%do%`

  i = seq_len(R+1)

  if(parallel && split.parallel){
    n <- max(foreach::getDoParWorkers(), split.parallel)
    message("Parallelisation: Task is split to ", n, " workers")
    i <- split(i, factor(sort(rank(i)%%n)))

    stats <- f1(foreach::foreach(i=i, .options.snow=list(preschedule=TRUE), .inorder = TRUE, .combine = cbind, .multicombine = TRUE, ...),
                foreach::`%do%`(foreach::foreach(j=i, .options.snow=list(preschedule=TRUE), .inorder = TRUE, .combine = cbind, .multicombine = TRUE, ...),
                do.call(statistic, c(list(Y=randrot(initialised.obj, I.matrix = (j == 1))), statistic.args)))
    )
  } else
    stats <- f1(foreach::foreach(i=i, .options.snow=list(preschedule=TRUE), .inorder = TRUE, .combine = cbind, .multicombine = TRUE, ...),
                do.call(statistic, c(list(Y=randrot(initialised.obj, I.matrix = (i == 1))), statistic.args))
    )

  ## The "statistic" function can return results with multiple columns:
  s0.i = 1:(ncol(stats)/(R+1))
  ncol.s = length(s0.i)
  s0 = stats[,s0.i,drop = FALSE]
  stats = stats[,-s0.i,drop = FALSE]

  stats = lapply(split(1:ncol(stats), factor((1:ncol(stats)-1) %% ncol.s)), function(i)stats[,i,drop=FALSE])


  new("rotate.stat", list(s0 = s0, stats = stats, ncol.s = ncol.s, R = R))
}




#' Random rotation matrix
#'
#' Generation of a random rotation matrix (random orthogonal matrix) distributed with haar measure.
#' @param n
#' @param type
#' @param I.matrix if \code{TRUE} return identity matrix.
#'
#' @return
#' @export
#' @details Adapted from pracma package (randortho function) (\code{\link[pracma:randortho]{randortho}})
#' \insertCite{Stewart1980a}{randRotation}
#'
#' @author Peter Hettegger
#' @examples
randorth <- function (n, type = c("orthonormal", "unitary"), I.matrix = FALSE)
{
  if(I.matrix) return(diag(n))
  ### this function was adapted from the pracma package (randortho function)

  stopifnot(is.numeric(n), length(n) == 1, floor(n) == ceiling(n),
            n >= 1)
  type <- match.arg(type)
  if (type == "orthonormal") {
    z <- matrix(rnorm(n^2), n)
  }
  else {
    z <- (matrix(rnorm(n^2), n) + (0+1i) * matrix(rnorm(n^2), n))
  }
  Z <- qr(z)
  q <- qr.Q(Z)
  r <- qr.R(Z)
  d <- diag(r)
  ph <- d/abs(d)
  q %*% diag(ph, length(ph))
}




#' Generate random permutation matrix for n samples
#'
#' Generate a random permutation matrix for \code{n} samples.
#'
#' @param n Number of samples
#'
#' @return A random permutation matrix
#' @export
#' @details This methods generates an orthogonal matrix with entries with only one entry in each row and column being \code{1}, all other entries being \code{0}.
#' @examples
#' design = model.matrix(~Species, iris)
#' randpermut(5)
#' @author Peter Hettegger
randpermut <- function(n){
  m1 = matrix(0,n,n)
  m1[cbind(1:n,sample(n))] = 1
  m1
}




#' Estimation of degrees of freedom for idempotent mapping
#'
#' @param initialised.obj
#' @param mapping An idempotent function which when applied to a matrix with \code{features x samples} dimensions returns a matrix of
#' transformed data with the same dimensions. Any further arguments can be passed to mapping through the mapping.args argument.
#' @param mapping.args List of arguments passed to mapping functin.
#' @param R Number of resampling replicates.
#'
#' @return A vector of estimated df for each feature.
#' @export
#'
#' @details The mapping/transformation function can also be approximately idempotent.
#'
#' @examples

#### Resampling ev durch bootstrap anstatt rotation ???? Was ist besser bzw. gibt es einen Vorteil/Nachteil ???
#### Weights implementieren !!! (siehe Paper) Im Prinzip muss nur die letzte Summe (dfs = rowSums(...)) mit den weights erweitert werden.
df.estimate = function(initialised.obj, mapping, mapping.args, R = 100){

  ### Berechnung über den "normalen Verschiebungssatz" ? --> (siehe z.B. Wikipedia Artikel "Verschiebungssatz")
  ### eventuell noch eine numerisch stabilere Variante implementieren (Stichwort "Auslöschung")

  y.t = randrot(initialised.obj)
  y.h = do.call(mapping, c(list(Y=y.t), mapping.args))


  #### mean estimation (für numerisch stabilere Version)
  #### die mean estimation könnte man eventuell noch weglassen (oder eleganter ausprogrammieren) ...
  for(i in 1:9){
    y.ti = randrot(initialised.obj)
    y.hi = do.call(mapping, c(list(Y=y.ti), trans.args))

    y.t = y.t + y.ti
    y.h = y.h + y.hi
  }
  y.t.mean = y.t/10
  y.h.mean = y.h/10
 #####################



  y.t = randrot(initialised.obj)
  y.h = do.call(mapping, c(list(Y=y.t), mapping.args))

  y.t = y.t - y.t.mean
  y.h = y.h - y.h.mean

  y.ht = y.h * y.t
  y.t2 = y.t^2


  for(i in 1:(R-1)){
    y.ti = randrot(initialised.obj)
    y.hi = do.call(mapping, c(list(Y=y.ti), trans.args))

    y.ti = y.ti - y.t.mean
    y.hi = y.hi - y.h.mean

    y.t = y.t + y.ti
    y.h = y.h + y.hi
    y.ht = y.ht + y.hi * y.ti

    y.t2 = y.t2 + y.ti^2
  }

  cov.yht = 1/(R-1) * y.ht - 1/(R * (R-1)) * y.h * y.t
  var.yt = 1/(R-1) * y.t2 - 1/(R * (R-1)) * y.t^2
  covs = cov.yht / var.yt

  dfs = rowSums(covs)
}

#
# .fdr.qu = function(s0, stats, ref.vector = NULL, na.rm = FALSE, beta = 0.05)
# {
#   if(is.null(ref.vector)){
#     ref.vector = sort(abs(s0[abs(s0) > 3]), decreasing = TRUE, na.last = TRUE)
#     ref.vector = c(ref.vector, seq(3,0,length.out = 100))
#   }
#
#   ref.vector.size = length(ref.vector)
#
#   r.vector = sapply(ref.vector, function(i) sum(abs(s0) > i))
#
#   qu.value <- vector("numeric", ref.vector.size)
#   est.95qu.exc <- vector("numeric", ref.vector.size)
#   su.hat <- vector("numeric", ref.vector.size)
#
#   ### ACHTUNG: Wie macht man das hier mit NAs (siehe Funktion .p.fdr) --> "res <- pmax(rowMeans(stats >= s0, na.rm = na.rm), 1/rowSums(!is.na(stats)), na.rm = na.rm)"
#
#   for (i in 1:ref.vector.size) {
#     v = colSums(abs(stats) > ref.vector[i])
#     est.95qu.exc[i] <- quantile(v, prob = (1 - beta),
#                                 names = FALSE)
#     su.hat[i] <- r.vector[i] - est.95qu.exc[i]
#     su.hat[i] <- ifelse(su.hat[i] < 0, 0, su.hat[i])
#     resamp.q <- ifelse((v + su.hat[i]) != 0, v/(v + su.hat[i]),
#                        0)
#     qu.value[i] <- mean(resamp.q)
#   }
#
#   #qu.value <- rev(cummin(rev(qu.value)))
#
#   approx(spline(ref.vector, qu.value), xout = abs(s0))$y
# }
#
# .fdr.q = function(s0, stats, ref.vector = NULL, na.rm = FALSE, beta = 0.05)
# {
#   if(is.null(ref.vector)){
#     ref.vector = sort(abs(s0[abs(s0) > 3]), decreasing = TRUE)
#     ref.vector = c(ref.vector, seq(3,0,length.out = 100))
#   }
#
#   ref.vector.size = length(ref.vector)
#
#   r.vector = sapply(ref.vector, function(i) sum(abs(s0) > i))
#
#   qu.value <- vector("numeric", ref.vector.size)
#   est.95qu.exc <- vector("numeric", ref.vector.size)
#   s.hat <- vector("numeric", ref.vector.size)
#
#   q.value <- vector("numeric", ref.vector.size)
#
#   for (i in 1:ref.vector.size) {
#     v = colSums(abs(stats) > ref.vector[i])
#     est.95qu.exc[i] <- quantile(v, prob = (1 - beta),
#                                 names = FALSE)
#     s.hat[i] <- r.vector[i] - mean(v)
#     s.hat[i] <- ifelse(s.hat[i] < est.95qu.exc[i], 0, s.hat[i])
#     resamp.q <- ifelse((v + s.hat[i]) != 0, v/(v + s.hat[i]),
#                        0)
#     q.value[i] <- mean(resamp.q)
#   }
#   #q.value <- rev(cummin(rev(q.value)))
#   approx(spline(ref.vector, q.value), xout = abs(s0))$y
#
# }


#' Internal function
#'
#' @param s0
#' @param stats
#' @param beta
#' @param na.rm
#' @param ref.vector NAs are removed from ref.vector
#'
#' @return
#'
#' @examples
.fdr.qu = function(s0, stats, beta = 0.05, na.rm = FALSE, ref.vector = sort(s0, decreasing = TRUE, na.last = TRUE))
{
  ref.vector = ref.vector[!is.na(ref.vector)]
  ref.vector.size = length(ref.vector)

  r.vector = sapply(ref.vector, function(i) sum(s0 >= i, na.rm = na.rm))

  qu.value <- vector("numeric", ref.vector.size)
  est.95qu.exc <- vector("numeric", ref.vector.size)
  su.hat <- vector("numeric", ref.vector.size)

  for (i in 1:ref.vector.size) {
    v = colSums(stats >= ref.vector[i], na.rm = na.rm)
    est.95qu.exc[i] <- quantile(v, prob = (1 - beta),
                                names = FALSE, na.rm = na.rm)
    su.hat[i] <- r.vector[i] - est.95qu.exc[i]
    su.hat[i] <- max(su.hat[i], 0, na.rm = na.rm) # su.hat smaller than 0 makes no sense
    resamp.q <- ifelse((v + su.hat[i]) != 0, v/(v + su.hat[i]),0)
    qu.value[i] <- mean(resamp.q, na.rm = na.rm)
  }

  qu.value <- cummax(qu.value)

  approx(spline(ref.vector, qu.value), xout = abs(s0))$y
}

.fdr.q = function(s0, stats, beta = 0.05, na.rm = FALSE, ref.vector = sort(s0, decreasing = TRUE, na.last = TRUE))
{
  ref.vector = ref.vector[!is.na(ref.vector)]
  ref.vector.size = length(ref.vector)

  r.vector = sapply(ref.vector, function(i) sum(s0 >= i, na.rm = na.rm))

  q.value <- vector("numeric", ref.vector.size)
  est.95qu.exc <- vector("numeric", ref.vector.size)
  s.hat <- vector("numeric", ref.vector.size)

  for (i in 1:ref.vector.size) {
    v = colSums(stats >= ref.vector[i], na.rm = na.rm)
    est.95qu.exc[i] <- quantile(v, prob = (1 - beta),
                                names = FALSE, na.rm = na.rm)
    s.hat[i] <- r.vector[i] - mean(v, na.rm = na.rm)
    s.hat[i] <- ifelse(s.hat[i] < est.95qu.exc[i], 0, s.hat[i])
    resamp.q <- ifelse((v + s.hat[i]) != 0, v/(v + s.hat[i]),
                       0)
    q.value[i] <- mean(resamp.q, na.rm = na.rm)
  }
  q.value <- rev(cummin(rev(q.value)))

  approx(spline(ref.vector, q.value), xout = abs(s0))$y
}

.p.fdr <- function(s0, stats, method, pooled, na.rm, beta){

  if(method %in% c("fdr.q", "fdr.qu") && pooled == FALSE) stop("Methods \"fdr.q\" and \"fdr.qu\" can only be used with pooled = TRUE")

  if(pooled == "FALSE"){
    res <- pmax(rowMeans(stats >= s0, na.rm = na.rm), 1/rowSums(!is.na(stats)), na.rm = na.rm)
    res <- p.adjust(p = res, method = method)
  } else {

    if(method == "fdr.q"){
      res <- .fdr.q(s0, stats, beta = beta, na.rm = na.rm)
    } else if(method == "fdr.qu"){
      res <- .fdr.qu(s0, stats, beta = beta, na.rm = na.rm)
    } else {
      if(na.rm == FALSE && any(is.na(stats))){
        #### Calculating p-values with "stats" containing NAs and "na.rm = FALSE" results in only NAs
        warning("NAs found in rotated stats.")
        res <- s0
        res[] <- NA
      } else {
        ### The "-" in ecdf and it's argument is necessary in order that the function behaves correctly for
        ### discrete statistics (i.e. in order that it is equivalent to ">=" instead of ">")
        ps <- ecdf(x = -stats)(-s0)
        res <- p.adjust(p = ps, method = method)
      }
    }
  }

  if(all(is.na(res))) warning("p-values / FDRs resulted only in NAs")

  res
}



#' Calculate resampling based p-values and FDRs
#'
#' This function calculates either (1) resampling based p-values with p-value adjustment using \link[stats:p.adjust]{stats::p.adjust} or (2) resampling based false-discovery-rates (FDRs) for rotated data.
#'
#'
#' @param obj A \code{rotate.stat} object produced by \link[randRotation:rotate.stat]{stats::p.adjust}.
#' @param method Can be either \code{"none"}, \code{"fdr.q"}, \code{"fdr.qu"} or any term that can be passed as \code{method} argument to \link[stats:p.adjust]{stats::p.adjust}, see \code{Details}. If \code{method = "none"}, resampling based
#' p-values without further adjustment are calculated.
#' @param pooled \code{logical}. \code{TRUE} (default) if marginal distributions are exchangeable for all features so that rotated stats can be pooled, see \code{Details}.
#' @param na.rm \code{logical}. \code{NA} values are ignored if set \code{TRUE}. \code{NA} values should be avoided and could e.g. be removed by imputation in original data or by removing features that contain \code{NA} values. Few \code{NA} values do not have a large effect, but many \code{NA} values can lead to wrong estimations of p-values and FDRs. We highly recommend avoiding \code{NA} values.
#' @param beta \code{numeric} between \code{0} and \code{1}. Corresponds to beta in .... cite Yekutieli and Benjamini paper here ....
#'
#' @return
#' @export
#' @seealso \code{\link[randRotation:rotate.stat]{rotate.stat}}
#' @details Larger values of obj$s0 are considered more significant when compared to the empirical distribution. E.g. for calculation of resampling based p-values (with \code{pooled = FALSE}) we in principle use
#' \code{p.val <- rowMeans(obj$stats >= obj$s0)}. We take \code{>=} instead of \code{>} when comparing rotated statistics against non-rotated statistics, as this is safer for discrete statistics.
#'
#' \code{method = "fdr.q"} and \code{method = "fdr.qu"} are resampling based fdr estimates and can only be used with \code{pooled = TRUE}. \code{method = "fdr.q"} is the FDR local estimator and \code{method = "fdr.qu"} is the FDR upper limit, see
#' .... cite (Reiner Yekutieli Benjamini) and (Yekutieli Benjamini) papers here ....
#' For all other \code{method} arguments resampling based p-values are calculated and passed to \link[stats:p.adjust]{stats::p.adjust} for p-value adjustment. So these methods provide resampling based p-values with (non-resampling based) p-value adjustment. When \code{pooled = TRUE}, marginal distributions of the test statistics are considered exchangeable for all features.
#' The resampling based p-values of each feature are then calculated from all rotated statistics (all features, all rotations). For these cases, if the number of features is reasonably large, usually only few resamples (argument \code{R} in \code{\link[randRotation:rotate.stat]{rotate.stat}}) are required.
#' When \code{pooled = FALSE} the resampling based p-values are calculcated for each feature separately.
#' This is required if one expects the resampling based statistics to be distributed differently for individual features. For most common applications this should not be the case and the marginal distribution are exchangeable for all features,
#' hence \code{pooled = TRUE} by default.
#' \code{method = "fdr.q"} and \code{method = "fdr.qu"} were adapted from package \code{fdrame} ( ... cite Reiner Yekutieli paper and FDRAME package here - including package version)
#' @examples
#' @author Peter Hettegger
p.fdr <- function(obj, method = "none", pooled = TRUE, na.rm = FALSE, beta = 0.05){
  if(!is(obj, "rotate.stat")) stop("class(obj) must be \"rotate.stat\"")
  if(beta < 0 || beta > 1) stop("beta must be between 0 and 1")
  if(any(is.na(obj$s0)) || any(is.na(unlist(obj$stats)))) warning("Missing values found in obj$s0 or obj$stats. Missing values are tolerated as much as possible, but should be avoided. See \"p.fdr\" help page.")



  method <- match.arg(method, c("fdr.q", "fdr.qu", stats::p.adjust.methods))

  res <- vapply(seq_len(obj$ncol.s),
                 function(i).p.fdr(obj$s0[,i,drop = TRUE], obj$stats[[i]], method, pooled, na.rm, beta),
                 obj$s0[,1])

  colnames(res) = colnames(obj$s0)
  res
}
#
# p.fdr.old <- function(obj, na.rm = FALSE){
#   if(!is(obj, "rotate.stat")) stop("class(obj) must be \"rotate.stat")
#
#   cols = seq(from = 1, to = ncol(obj$stats), by = obj$ncol.s)
#   if(any(rowSums(!is.na(obj$stats)) < 1)) warning("At least one row in stats contains only NAs.")
#
#   ps <- sapply(1:obj$ncol.s-1, function(i){
#     pmax(rowMeans(abs(obj$stats[,cols+i]) >= abs(obj$s0[,i+1]), na.rm = na.rm), 1/rowSums(!is.na(obj$stats[,cols+i])))
#   })
#
# }


### inspired by the man page of qqplot
#' QQ plot of data sample against uniform theoretical quantiles
#'
#' @param ps
#' @param log
#' @param variable
#'
#' @return
#' @export
#'
#' @examples
qqunif = function(ps, log = "xy", pch = 19, xlab = "theoretical quantiles",
ylab = "sample quantiles", ...){
  ## Q-Q plot for Unif data against true theoretical distribution
  qqplot(ppoints(ps), ps, main = expression("Q-Q plot for" ~~ {Unif(0,1)}),
         log = log, pch = pch, xlab = xlab, ylab = ylab, ...)
  qqline(ps, distribution = function(p) qunif(p),
         probs = c(0.1, 0.6), col = "salmon", lwd = 2)
}




