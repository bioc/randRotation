@article{Langsrud2005,
abstract = {This paper describes a generalised framework for doing Monte Carlo tests in multivariate linear regression.Therotation methodologyassumes multivariate normality and is a true generalisation of the classical multivariate tests - any imaginable test statistic is allowed. The generalised test statistics are dependent on the unknown covariance matrix. Rotation testing handles this problem by conditioning on sufficient statistics. Compared to permutation tests, we replace permutations by proper random rotations. Permutation tests avoid the multinormal assumption, but they are limited to relatively simple models. On the other hand, a rotation test can, in particular, be applied to any multivariate generalisation of the univariate F-test. As an important application, a detailed description of howeach single response p-value can be non- conservatively adjusted for multiplicity is given. This method is exact and non-conservative (unlike Bonferroni), and it is a generalisation of the ordinary F-test (except for the computation by simulations). Hence, this paper offers an exact Monte Carlo solution to a classical problem of multiple testing.},
author = {Langsrud, Oyvind},
doi = {10.1007/s11222-005-4789-5},
file = {:C$\backslash$:/Users/hetteggerp/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Langsrud{\_}2005{\_}Rotation tests.pdf:pdf},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Adjusted p-value,Conditional inference,Microarray data analysis,Multiple endpoints,Multiple testing,Random orthogonal matrix,Spherical distribution},
number = {1},
pages = {53--60},
title = {{Rotation tests}},
volume = {15},
year = {2005}
}

@article{Law2014,
abstract = {New normal linear modeling strategies are presented for analyzing read counts from RNA-seq experiments. The voom method estimates the mean-variance relationship of the log-counts, generates a precision weight for each observation and enters these into the limma empirical Bayes analysis pipeline. This opens access for RNA-seq analysts to a large body of methodology developed for microarrays. Simulation studies show that voom performs as well or better than count-based RNA-seq methods even when the data are generated according to the assumptions of the earlier methods. Two case studies illustrate the use of linear modeling and gene set testing methods.},
author = {Law, Charity W. and Chen, Yunshun and Shi, Wei and Smyth, Gordon K.},
doi = {10.1186/gb-2014-15-2-r29},
file = {:C$\backslash$:/Users/hetteggerp/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Law et al.{\_}2014{\_}Voom Precision weights unlock linear model analysis tools for RNA-seq read counts.pdf:pdf},
isbn = {1465-6906},
issn = {1474760X},
journal = {Genome Biology},
number = {2},
pages = {1--17},
pmid = {24485249},
title = {{Voom: Precision weights unlock linear model analysis tools for RNA-seq read counts}},
volume = {15},
year = {2014}
}

@article{Stewart1980a,
abstract = {This paper presents a method for generating pseudo-random orthogonal matrices from the Haar distribution for the group of orthogonal matrices. The random matrices are exoressed as oroducts of n -1 Householder transformations, which can be computed in O(n{\^{}}2) time. The technique is used in an empirical study of two methods for estimating the condition number of a matrix.},
author = {Stewart, G W},
doi = {10.1137/0717034},
file = {:C$\backslash$:/Users/hetteggerp/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Stewart{\_}1980{\_}The Efficient Generation of Random Orthogonal Matrices with an Application to Condition Estimators.pdf:pdf},
isbn = {00361429},
issn = {0036-1429},
journal = {SIAM Journal on Numerical Analysis},
title = {{The Efficient Generation of Random Orthogonal Matrices with an Application to Condition Estimators}},
year = {1980}
}

@article{Reiner2003,
abstract = {Motivation: DNA microarrays have recently been used for the purpose of monitoring expression levels of thousands of genes simultaneously and identifying those genes that are differentially expressed. The probability that a false identification (type I error) is committed can increase sharply when the number of tested genes gets large. Correlation between the test statistics attributed to gene co-regulation and dependency in the measurement errors of the gene expression levels further complicates the problem. In this paper we address this very large multi-plicity problem by adopting the false discovery rate (FDR) controlling approach. In order to address the dependency problem, we present three resampling-based FDR con-trolling procedures, that account for the test statistics distribution, and compare their performance to that of the nave application of the linear step-up procedure in Ben-jamini and Hochberg (1995). The procedures are studied using simulated microarray data, and their performance is examined relative to their ease of implementation. Results: Comparative simulation analysis shows that all four FDR controlling procedures control the FDR at the desired level, and retain substantially more power then the family-wise error rate controlling procedures. In terms of power, using resampling of the marginal distribution of each test statistics substantially improves the performance over the nave one. The highest power is achieved, at the expense of a more sophisticated algorithm, by the resampling-based procedures that resample the joint distribution of the test statistics and estimate the level of FDR control. Availability: An R program that adjusts p-values using FDR controlling procedures is freely available over the Internet at www.math.tau.ac.il/âˆ¼ybenja.},
author = {Reiner, Anat and Yekutieli, Daniel and Benjamini, Yoav},
doi = {10.1093/bioinformatics/btf877},
file = {:C$\backslash$:/Users/phett/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Reiner, Yekutieli, Benjamini{\_}2003{\_}Identifying differentially expressed genes using false discovery rate controlling procedures.pdf:pdf},
isbn = {1367-4803},
issn = {13674803},
journal = {Bioinformatics},
number = {3},
pages = {368--375},
pmid = {12584122},
title = {{Identifying differentially expressed genes using false discovery rate controlling procedures}},
volume = {19},
year = {2003}
}
@article{Yekutieli1999,
abstract = {A new false discovery rate controlling procedure is proposed for multiple hypotheses testing. The procedure makes use of resampling-based p-value adjustment, and is designed to cope with correlated test statistics. Some properties of the proposed procedure are investigated theoretically, and further properties are investigated using a simulation study. According to the results of the simulation study, the new procedure offers false discovery rate control and greater power. The motivation for developing this resampling-based procedure was an actual problem in meteorology, in which almost 2000 hypotheses are tested simultaneously using highly correlated test statistics. When applied to this problem the increase in power was evident. The same procedure can be used in many other large problems of multiple testing, for example multiple endpoints. The procedure is also extended to serve as a general diagnostic tool in model selection.},
author = {Yekutieli, Daniel and Benjamini, Yoav},
doi = {10.1016/S0378-3758(99)00041-5},
file = {:C$\backslash$:/Users/phett/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Yekutieli, Benjamini{\_}1999{\_}Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics.pdf:pdf},
isbn = {0378-3758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {meteorology,model selection,multiple comparisons,multiple endpoints},
number = {1-2},
pages = {171--196},
pmid = {83580500015},
title = {{Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics}},
volume = {82},
year = {1999}
}

@Manual{Fdrame2019,
    title = {fdrame: FDR adjustments of Microarray Experiments (FDR-AME)},
    author = {Yoav Benjamini and Effi Kenigsberg and Anat Reiner and Daniel Yekutieli},
    year = {2019},
    note = {R package version 1.56.0},
  }

@article{Mezzadri2007,
abstract = {We discuss how to generate random unitary matrices from the classical compact groups U(N), O(N) and USp(N) with probability distributions given by the respective invariant measures. The algorithm is straightforward to implement using standard linear algebra packages. This approach extends to the Dyson circular ensembles too. This article is based on a lecture given by the author at the summer school on Number Theory and Random Matrix Theory held at the University of Rochester in June 2006. The exposition is addressed to a general mathematical audience.},
archivePrefix = {arXiv},
arxivId = {math-ph/0609050},
author = {Mezzadri, Francesco},
eprint = {0609050},
file = {:C$\backslash$:/Users/phett/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Mezzadri{\_}2007{\_}How to generate random matrices from the classical compact groups.pdf:pdf},
issn = {1088-9477},
journal = {Notices of the American Mathematical Society},
number = {5},
pages = {592--604},
primaryClass = {math-ph},
title = {{How to generate random matrices from the classical compact groups}},
url = {http://arxiv.org/abs/math-ph/0609050},
volume = {54},
year = {2007}
}

@article{Ritchie2015,
author = {Ritchie, Matthew E and Phipson, Belinda and Wu, Di and Hu, Yifang and Law, Charity W and Shi, Wei and Smyth, Gordon K},
journal = {Nucleic Acids Research},
number = {7},
pages = {e47},
title = {{limma powers differential expression analyses for RNA-sequencing and microarray studies}},
volume = {43},
year = {2015}
}

@article{Johnson2007,
abstract = {Non-biological experimental variation or "batch effects" are commonly observed across multiple batches of microarray experiments, often rendering the task of combining data from these batches difficult. The ability to combine microarray data sets is advantageous to researchers to increase statistical power to detect biological phenomena from studies where logistical considerations restrict sample size or in studies that require the sequential hybridization of arrays. In general, it is inappropriate to combine data sets without adjusting for batch effects. Methods have been proposed to filter batch effects from data, but these are often complicated and require large batch sizes ( {\textgreater} 25) to implement. Because the majority of microarray studies are conducted using much smaller sample sizes, existing methods are not sufficient. We propose parametric and non-parametric empirical Bayes frameworks for adjusting data for batch effects that is robust to outliers in small sample sizes and performs comparable to existing methods for large samples. We illustrate our methods using two example data sets and show that our methods are justifiable, easy to apply, and useful in practice. Software for our method is freely available at: http://biosun1.harvard.edu/complab/batch/.},
author = {Johnson, W. Evan and Li, Cheng and Rabinovic, Ariel},
doi = {10.1093/biostatistics/kxj037},
file = {:C$\backslash$:/Users/phett/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Johnson, Li, Rabinovic{\_}2007{\_}Adjusting batch effects in microarray expression data using empirical Bayes methods.pdf:pdf},
issn = {14654644},
journal = {Biostatistics},
keywords = {Batch effects,Empirical Bayes,Microarrays,Monte Carlo},
pages = {118--127},
pmid = {16632515},
title = {{Adjusting batch effects in microarray expression data using empirical Bayes methods}},
volume = {8},
year = {2007}
}

@article{Nygaard2015,
abstract = {Removal of, or adjustment for, batch effects or center differences is generally required when such effects are present in data. In particular, when preparing microarray gene expression data from multiple cohorts, array platforms, or batches for later analyses, batch effects can have confounding effects, inducing spurious differences between study groups. Many methods and tools exist for removing batch effects from data. However, when study groups are not evenly distributed across batches, actual group differences may induce apparent batch differences, in which case batch adjustments may bias, usually deflate, group differences. Some tools therefore have the option of preserving the difference between study groups, e.g. using a two-way ANOVA model to simultaneously estimate both group and batch effects. Unfortunately, this approach may systematically induce incorrect group differences in downstream analyses when groups are distributed between the batches in an unbalanced manner. The scientific community seems to be largely unaware of how this approach may lead to false discoveries.},
author = {Nygaard, Vegard and R{\o}dland, Einar Andreas and Hovig, Eivind},
doi = {10.1093/biostatistics/kxv027},
file = {:C$\backslash$:/Users/phett/Desktop/Skripten{\_}Ebooks/Mendeley{\_}bib/Nygaard, R{\o}dland, Hovig{\_}2015{\_}Methods that remove batch effects while retaining group differences may lead to exaggerated confidence in d.pdf:pdf},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {batch effects,data normalization,microarrays,reproducible research},
number = {April 2016},
pages = {kxv027},
pmid = {26272994},
title = {{Methods that remove batch effects while retaining group differences may lead to exaggerated confidence in downstream analyses.}},
url = {http://biostatistics.oxfordjournals.org/lookup/doi/10.1093/biostatistics/kxv027{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26272994},
year = {2015}
}


